This is a **structured, comprehensive overview** of the major **features, functions, classes, and modules** provided by **scikit-learn (sklearn)** for building and working with machine-learning models.
This is not an exhaustive list but covers the essential and widely used components.

---

# âœ… **1. Core Modules of scikit-learn**

Scikit-learn is organized into subpackages. The major ones include:

---

## **1.1 sklearn.datasets**

Tools for loading and generating datasets.

**Key functions:**

* `load_iris()`, `load_wine()`, `load_breast_cancer()`
* `load_digits()`, `load_diabetes()`
* `fetch_20newsgroups()`, `fetch_openml()`
* Synthetic dataset generators:

  * `make_classification()`
  * `make_regression()`
  * `make_blobs()`
  * `make_moons()`
  * `make_circles()`

---

## **1.2 sklearn.model_selection**

Tools for splitting data and evaluating models.

**Key functions and classes:**

* **Train-test splitting**

  * `train_test_split()`
* **Cross-validation**

  * `cross_val_score()`
  * `cross_validate()`
  * `LearningCurveDisplay`, `ValidationCurveDisplay`
* **Hyperparameter search**

  * `GridSearchCV`
  * `RandomizedSearchCV`
  * `HalvingGridSearchCV`
  * `HalvingRandomSearchCV`
* **Split strategies:**

  * `KFold`, `StratifiedKFold`
  * `GroupKFold`, `TimeSeriesSplit`
  * `ShuffleSplit`, `StratifiedShuffleSplit`

---

## **1.3 sklearn.preprocessing**

Transformers for feature scaling and encoding.

**Scaling & normalization:**

* `StandardScaler`
* `MinMaxScaler`
* `RobustScaler`
* `Normalizer`
* `QuantileTransformer`
* `PowerTransformer`

**Encoding:**

* `OneHotEncoder`
* `OrdinalEncoder`
* `LabelEncoder`
* `LabelBinarizer`

**Feature engineering:**

* `PolynomialFeatures`
* `Binarizer`
* `KBinsDiscretizer`

---

## **1.4 sklearn.impute**

Tools for missing-value imputation.

* `SimpleImputer`
* `KNNImputer`
* `IterativeImputer`
* `MissingIndicator`

---

## **1.5 sklearn.pipeline**

Pipeline utilities to chain preprocessing + models.

* `Pipeline`
* `make_pipeline()`
* `FeatureUnion`
* `ColumnTransformer`
* `make_column_transformer()`

---

## **1.6 sklearn.feature_selection**

Tools for selecting important features.

* **Filter methods:**

  * `SelectKBest`, `SelectPercentile`
  * `chi2`, `f_regression`, `f_classif`
* **Wrapper methods:**

  * `RFE`, `RFECV`
* **Embedded methods:**

  * `SelectFromModel`
* **Model-specific selectors:**

  * L1-based selection using `Lasso`
  * Tree-based selection using `RandomForestClassifier`

---

## **1.7 sklearn.decomposition**

Dimensionality reduction methods.

* `PCA`, `IncrementalPCA`, `KernelPCA`
* `TruncatedSVD`
* `NMF`
* `FactorAnalysis`
* `FastICA`
* `DictionaryLearning`

---

## **1.8 sklearn.metrics**

Evaluation metrics for regression, classification, clustering.

**Classification:**

* `accuracy_score`
* `precision_score`, `recall_score`, `f1_score`
* `confusion_matrix`
* `classification_report`
* `roc_curve`, `auc`
* `log_loss`

**Regression:**

* `mean_squared_error`
* `mean_absolute_error`
* `r2_score`

**Clustering:**

* `silhouette_score`
* `calinski_harabasz_score`
* `davies_bouldin_score`

---

## **1.9 sklearn.linear_model**

Linear models for regression and classification.

### Regression:

* `LinearRegression`
* `Ridge`, `Lasso`, `ElasticNet`
* `BayesianRidge`
* `SGDRegressor`
* `HuberRegressor`

### Classification:

* `LogisticRegression`
* `LinearSVC`
* `RidgeClassifier`
* `SGDClassifier`
* `Perceptron`

---

## **1.10 sklearn.tree**

Decision trees.

* `DecisionTreeClassifier`
* `DecisionTreeRegressor`
* `plot_tree()`

---

## **1.11 sklearn.ensemble**

Ensemble methods.

### Bagging methods:

* `BaggingClassifier`, `BaggingRegressor`
* `RandomForestClassifier`, `RandomForestRegressor`
* `ExtraTreesClassifier`, `ExtraTreesRegressor`

### Boosting:

* `AdaBoostClassifier`, `AdaBoostRegressor`
* `GradientBoostingClassifier`
* `GradientBoostingRegressor`

### Stacking & Voting:

* `StackingClassifier`, `StackingRegressor`
* `VotingClassifier`, `VotingRegressor`

---

## **1.12 sklearn.svm**

Support Vector Machines.

* `SVC` (classification)
* `SVR` (regression)
* `LinearSVC`
* `OneClassSVM` (outlier detection)

---

## **1.13 sklearn.neighbors**

K-Nearest Neighbors algorithms.

* `KNeighborsClassifier`
* `KNeighborsRegressor`
* `NearestNeighbors`
* `RadiusNeighborsClassifier`
* `KDTree`, `BallTree`

---

## **1.14 sklearn.naive_bayes**

NaÃ¯ve Bayes models.

* `GaussianNB`
* `MultinomialNB`
* `BernoulliNB`
* `ComplementNB`
* `CategoricalNB`

---

## **1.15 sklearn.cluster**

Clustering algorithms.

* `KMeans`
* `MiniBatchKMeans`
* `DBSCAN`
* `OPTICS`
* `MeanShift`
* `AgglomerativeClustering`
* `SpectralClustering`
* `Birch`

---

## **1.16 sklearn.manifold**

Manifold learning & nonlinear dimensionality reduction.

* `TSNE`
* `Isomap`
* `LocallyLinearEmbedding (LLE)`
* `MDS`

---

## **1.17 sklearn.covariance**

Covariance estimators & anomaly detection.

* `EllipticEnvelope`
* `LedoitWolf`, `OAS`
* `GraphicalLasso`

---

## **1.18 sklearn.semi_supervised**

Semi-supervised learning.

* `LabelSpreading`
* `LabelPropagation`
* `SelfTrainingClassifier`

---

## **1.19 sklearn.gaussian_process**

Gaussian process regression and classification.

* `GaussianProcessRegressor`
* `GaussianProcessClassifier`
* Kernels: `RBF`, `Matern`, `RationalQuadratic`

---

## **1.20 sklearn.inspection**

Model interpretation tools.

* `permutation_importance`
* `PartialDependenceDisplay`
* `DecisionBoundaryDisplay`

---

## **1.21 sklearn.utils**

Utility functions (mixins, random generators, validation helpers).

* `shuffle`
* `resample`
* `check_array`
* `all_estimators`

---

# ğŸ¯ Summary Table

| Category                 | Key Tools                                                       |
| ------------------------ | --------------------------------------------------------------- |
| Data                     | `datasets`, `make_*` functions                                  |
| Prep / Cleaning          | `preprocessing`, `impute`, `feature_selection`                  |
| Model Training           | `linear_model`, `svm`, `neighbors`, `tree`, `ensemble`          |
| Model Evaluation         | `model_selection`, `metrics`                                    |
| Dimensionality Reduction | `PCA`, `SVD`, `NMF`, `t-SNE`, `LLE`                             |
| Pipelines                | `Pipeline`, `ColumnTransformer`                                 |
| Advanced                 | `gaussian_process`, `manifold`, `covariance`, `semi_supervised` |

---

Below is an **expanded list** of scikit-learn featuresâ€”covering more modules, utilities, helper classes, configuration tools, meta-estimators, datasets, inspection tools, and lesser-known functionalities. This list goes **beyond the common APIs** and includes more detailed internal and advanced components.

---

# ğŸ”¥ **Additional and More Advanced scikit-learn Features**

---

# âœ… **2. Extended and Advanced Preprocessing Features**

## **2.1 Feature Scaling & Transformation**

* `MaxAbsScaler`
* `FunctionTransformer`
* `SplineTransformer`
* `KBinsDiscretizer`
* `PolynomialCountSketch`

---

## **2.2 Encoding & Categorical Handling**

* `MultiLabelBinarizer`
* `DictVectorizer`
* `FeatureHasher`

---

## **2.3 Text Preprocessing**

(from `sklearn.feature_extraction.text`)

* `CountVectorizer`
* `TfidfVectorizer`
* `TfidfTransformer`
* `HashingVectorizer`
* `ENGLISH_STOP_WORDS`

---

## **2.4 Image Feature Extraction**

(from `sklearn.feature_extraction.image`)

* `img_to_graph`
* `grid_to_graph`
* `extract_patches_2d`
* `PatchExtractor`

---

## **2.5 Feature Extraction (General)**

(from `sklearn.feature_extraction`)

* `DictVectorizer`
* `FeatureHasher`

---

# âœ… **3. Expanded Model Selection Tools**

* `ParameterGrid`
* `ParameterSampler`
* `learning_curve()`
* `validation_curve()`
* `permutation_test_score()`

---

# âœ… **4. Transformers & Meta-Estimators**

Meta-estimators wrap other models:

* `TransformedTargetRegressor`
* `MultiOutputRegressor`
* `MultiOutputClassifier`
* `ClassifierChain`
* `RegressorChain`
* `OneVsOneClassifier`
* `OneVsRestClassifier`
* `OutputCodeClassifier`
* `CalibratedClassifierCV`

---

# âœ… **5. More Linear Models**

### **Generalized Linear Models**

* `PoissonRegressor`
* `GammaRegressor`
* `TweedieRegressor`

### **Outlier-robust linear models**

* `RANSACRegressor`
* `QuantileRegressor`
* `TheilSenRegressor`

---

# âœ… **6. More Tree & Ensemble Tools**

### Extra decision tree utilities:

* `plot_tree`
* `export_graphviz`
* `export_text`

### Extra ensemble utilities:

* `HistGradientBoostingClassifier`
* `HistGradientBoostingRegressor`

---

# âœ… **7. Expanded Clustering Features**

### Specialized clustering methods:

* `AffinityPropagation`
* `OPTICS`
* `AgglomerativeClustering`
* `SpectralClustering`
* `BisectingKMeans`

### Pairwise metrics for clustering:

(from `sklearn.metrics.pairwise`)

* `pairwise_distances`
* `pairwise_kernels`
* `cosine_similarity`
* `rbf_kernel`
* `linear_kernel`
* `polynomial_kernel`

---

# âœ… **8. Model Persistence / Saving Models**

Scikit-learn provides:

* `joblib.dump()`
* `joblib.load()`

Also works with:

* `pickle`

---

# âœ… **9. Calibration and Probability Tools**

* `CalibratedClassifierCV`
* `calibration_curve`

---

# âœ… **10. Imbalanced Data Handling (partially via external libs)**

scikit-learn natively supports:

* `class_weight="balanced"` option in many models
* `sample_weight` parameters
* `compute_class_weight`
* `compute_sample_weight`

(For advanced imbalance handling, `imblearn` complements sklearn.)

---

# âœ… **11. Outlier Detection / Novelty Detection**

### Built-in methods include:

* `OneClassSVM`
* `IsolationForest`
* `LocalOutlierFactor`
* `EllipticEnvelope`
* `RobustRandomCutForest` (in future versions)

---

# âœ… **12. Model Inspection and Visualization**

More tools in `sklearn.inspection`:

* `plot_partial_dependence`
* `PartialDependenceDisplay`
* `DecisionBoundaryDisplay`
* `permutation_importance`

---

# âœ… **13. Utilities for Pairwise Computation**

Additional pairwise computing tools:

* `pairwise_distances_argmin`
* `pairwise_distances_argmin_min`
* `pairwise_distances_chunked`
* `euclidean_distances`

---

# âœ… **14. Advanced Dataset Utilities**

Beyond the common datasets:

### Real-world datasets:

* `fetch_covtype()`
* `fetch_kddcup99()`
* `fetch_rcv1()`
* `fetch_lfw_people()`
* `fetch_lfw_pairs()`

### Data loader helper functions:

* `load_files`
* `load_svmlight_file`
* `dump_svmlight_file`

---

# âœ… **15. Configuration, Validation, and Introspection Tools**

### Global configuration:

* `set_config`
* `get_config`
* `config_context`

### Validation helpers:

* `check_X_y`
* `check_array`
* `check_is_fitted`

### Introspection:

* `all_estimators()`
* `all_displays()`

---

# âœ… **16. Advanced Pipelines / Feature Union Tools**

* `FeatureUnion`
* `ColumnTransformer`
* `make_column_selector()`
* `clone` (creates deep copies of models)
* `Memory` (caches pipeline steps)

---

# ğŸ”¥ BONUS: Hidden/Low-Level Utilities Most People Donâ€™t Know

* `sklearn.base` (Base classes for estimators)

  * `BaseEstimator`
  * `ClassifierMixin`
  * `RegressorMixin`
  * `TransformerMixin`

* `sklearn.utils.extmath`

  * `randomized_svd`
  * `density`
  * `fast_logdet`

* `sklearn.utils.parallel_backend` for controlling joblib parallelism

* `sklearn.utils.fixes` internal compatibility helpers

---

# ğŸ”¥ **17. sklearn.kernel_approximation**

Approximate kernel mappings for speeding up SVMs and kernel methods.

### Kernel approximation transformers:

* `RBFSampler`
* `SkewedChi2Sampler`
* `Nystroem`
* `AdditiveChi2Sampler`

---

# ğŸ”¥ **18. sklearn.kernel_ridge**

Kernel Ridge Regression:

* `KernelRidge`

---

# ğŸ”¥ **19. sklearn.random_projection**

Dimensionality reduction using random projections.

### Transformers:

* `GaussianRandomProjection`
* `SparseRandomProjection`

Utility:

* `johnson_lindenstrauss_min_dim`

---

# ğŸ”¥ **20. sklearn.preprocessing._discretization (advanced discretization)**

Internal utilities for binning:

* `KBinsDiscretizer` (already listed)
* `PolynomialCountSketch`
* `_encode`, `_encode_numpy` (internal helpers)

---

# ğŸ”¥ **21. sklearn.feature_extraction.text (expanded)**

Advanced text utilities:

* `HashingVectorizer`
* `TfidfVectorizer`
* `CountVectorizer`
* `strip_accents_unicode`, `strip_accents_ascii`
* `iter_files`
* Stop-word lists (`ENGLISH_STOP_WORDS`)

---

# ğŸ”¥ **22. sklearn.feature_extraction.image (expanded)**

Advanced functions:

* `PatchExtractor`
* `extract_patches_2d`
* `reconstruct_from_patches_2d`
* `img_to_graph`
* `grid_to_graph`

---

# ğŸ”¥ **23. sklearn.metrics (expanded)**

### Ranking Metrics:

* `dcg_score`
* `ndcg_score`
* `label_ranking_average_precision_score`
* `label_ranking_loss`
* `coverage_error`

### Distance Metrics:

* `euclidean_distances`
* `manhattan_distances`
* `haversine_distances`
* `pairwise_distances`
* `pairwise_kernels`

### Clustering Metrics:

* `adjusted_rand_score`
* `adjusted_mutual_info_score`
* `homogeneity_score`
* `completeness_score`
* `v_measure_score`

### Plotting Tools:

* `ConfusionMatrixDisplay`
* `RocCurveDisplay`
* `PrecisionRecallDisplay`

---

# ğŸ”¥ **24. sklearn.discriminant_analysis**

Linear and quadratic discriminant analysis:

* `LinearDiscriminantAnalysis`
* `QuadraticDiscriminantAnalysis`

---

# ğŸ”¥ **25. sklearn.multiclass**

Multiclass and multilabel strategies:

* `OneVsRestClassifier`
* `OneVsOneClassifier`
* `OutputCodeClassifier`

---

# ğŸ”¥ **26. sklearn.multioutput**

Handling multiple output regression and classification:

* `MultiOutputRegressor`
* `MultiOutputClassifier`
* `RegressorChain`
* `ClassifierChain`

---

# ğŸ”¥ **27. sklearn.calibration**

Probability calibration tools:

* `CalibratedClassifierCV`
* `calibration_curve`

---

# ğŸ”¥ **28. sklearn.compose**

Column-wise transformations and pipelines:

* `ColumnTransformer`
* `make_column_transformer`
* `make_column_selector`
* `TransformedTargetRegressor`

---

# ğŸ”¥ **29. sklearn.exceptions**

Custom scikit-learn warnings and errors:

* `NotFittedError`
* `ConvergenceWarning`
* `DataConversionWarning`
* `FitFailedWarning`
* `UndefinedMetricWarning`

---

# ğŸ”¥ **30. sklearn.neural_network**

Light neural network models:

* `MLPClassifier`
* `MLPRegressor`
* Activation functions:

  * `relu`
  * `identity`
  * `tanh`
  * `logistic`

---

# ğŸ”¥ **31. sklearn._loss (private API)**

Advanced loss functions used internally:

* `HalfSquaredLoss`
* `SquaredLoss`
* `AbsoluteLoss`
* `PinballLoss`
* `HuberLoss`

*(Used for gradient boosting and hist boosting.)*

---

# ğŸ”¥ **32. sklearn.semi_supervised (expanded)**

Semi-supervised learning:

* `SelfTrainingClassifier`
* `LabelSpreading`
* `LabelPropagation`

Supports kernels:

* `rbf`
* `knn`

---

# ğŸ”¥ **33. sklearn.impute (expanded)**

Advanced options:

* `IterativeImputer` (MICE-like)
* `MissingIndicator`
* `KNNImputer`

Supports:

* `add_indicator=True`

---

# ğŸ”¥ **34. sklearn.manifold (expanded)**

Advanced nonlinear dimension reduction:

* `Isomap`
* `LocallyLinearEmbedding`
* `ModifiedLLE`
* `HessianLLE`
* `SpectralEmbedding`
* `TSNE`
* `MDS`

---

# ğŸ”¥ **35. sklearn.covariance (expanded)**

Covariance estimators:

* `GraphicalLasso`
* `GraphicalLassoCV`
* `ShrunkCovariance`
* `EllipticEnvelope`
* `MinCovDet`
* `EmpiricalCovariance`
* `OAS`
* `LedoitWolf`

---

# ğŸ”¥ **36. sklearn.cluster (expanded)**

Additional clustering utilities:

* `Birch`
* `OPTICS`
* `SpectralClustering`
* `MeanShift`
* `AgglomerativeClustering`

Distance and connectivity helpers:

* `kneighbors_graph`
* `connectivity`

---

# ğŸ”¥ **37. sklearn.gaussian_process (expanded)**

GP models:

* `GaussianProcessClassifier`
* `GaussianProcessRegressor`

Kernels:

* `RBF`
* `Matern`
* `WhiteKernel`
* `RationalQuadratic`
* `ExpSineSquared`
* `DotProduct`
* `ConstantKernel`

---

# ğŸ”¥ **38. sklearn.utils (expanded)**

### Utility functions:

* `check_random_state`
* `shuffle`, `resample`
* `column_or_1d`
* `compute_class_weight`
* `compute_sample_weight`
* `as_float_array`

### Metadata routing (advanced feature):

* `set_config(enable_metadata_routing=True)`
* `metadata_routing`
* `MethodMapping`

---

# ğŸ”¥ **39. sklearn.base (expanded)**

Base classes that define estimator behavior:

* `BaseEstimator`
* `ClassifierMixin`
* `RegressorMixin`
* `TransformerMixin`
* `ClusterMixin`

Utility methods offered by all estimators:

* `get_params()`
* `set_params()`

---

# ğŸ”¥ **40. sklearn.inspection (expanded)**

Advanced model interpretability tools:

* `partial_dependence`
* `PartialDependenceDisplay`
* `permutation_importance`
* `DecisionBoundaryDisplay`

---

# ğŸ”¥ **41. sklearn.exceptions & warnings (expanded)**

Special exception types:

* `PositiveSpectrumKernelWarning`
* `BiasVsVarianceWarning`

---

# ğŸ”¥ **42. sklearn._config (low level)**

Global configuration API:

* `get_config()`
* `set_config()`
* `config_context()`

---

# ğŸ”¥ **43. sklearn.experimental**

Experimental features:

* `enable_hist_gradient_boosting`
* `enable_iterative_imputer`

---

# ğŸ”¥ **44. sklearn.externals (deprecated)**

Previously included:

* `joblib`

---

# ğŸ”¥ **45. sklearn.tree (expanded)**

Tree utilities:

* `ExtraTreeClassifier`
* `ExtraTreeRegressor`

Visualization tools:

* `export_text`
* `export_graphviz`
* `plot_tree`

---

# ğŸ”¥ **46. sklearn.svm (expanded)**

Support for kernels:

* `precomputed` kernel option
* `probability=True` for probability estimates
* `decision_function_shape` ("ovr" or "ovo")

---

# ğŸ”¥ **47. sklearn.neighbors (expanded)**

Additional tools:

* `NearestCentroid`
* `BallTree`, `KDTree`
* `RadiusNeighborsClassifier`
* `RadiusNeighborsRegressor`

---

# ğŸ”¥ **48. sklearn.ensemble (expanded)**

Boosting extras:

* `HistGradientBoostingClassifier`
* `HistGradientBoostingRegressor`
* `IsolationForest`
* `VotingRegressor`

---

# ğŸ”¥ **49. sklearn._openmp_helpers**

Internal utility to check OpenMP availability.

---

# ğŸ”¥ **50. sklearn.utils.fixes**

Internal patches to handle:

* SciPy changes
* NumPy changes
* joblib compatibility

---

# ğŸ¯ SUMMARY

We've now listed at least **50 major categories** and **hundreds** of classes, functions, utilities, meta-estimators, helpers, and internal functionality inside scikit-learn.

---

This is a **FULL HIERARCHICAL LIST** of scikit-learn modules, submodules, classes, functions, and utilities â€” organized by package and in a tree-like structure.
This is the **most complete, structured breakdown** you can get without automatically scraping the library.

---

# ğŸŒ³ **FULL HIERARCHICAL STRUCTURE OF SCIKIT-LEARN**

---

# 1. **sklearn**

Top-level namespace containing subpackages:

```
sklearn
â”‚
â”œâ”€â”€ base
â”œâ”€â”€ calibration
â”œâ”€â”€ cluster
â”œâ”€â”€ compose
â”œâ”€â”€ covariance
â”œâ”€â”€ cross_decomposition
â”œâ”€â”€ datasets
â”œâ”€â”€ decomposition
â”œâ”€â”€ discriminant_analysis
â”œâ”€â”€ dummy
â”œâ”€â”€ ensemble
â”œâ”€â”€ exceptions
â”œâ”€â”€ experimental
â”œâ”€â”€ feature_extraction
â”œâ”€â”€ feature_selection
â”œâ”€â”€ gaussian_process
â”œâ”€â”€ impute
â”œâ”€â”€ inspection
â”œâ”€â”€ isotonic
â”œâ”€â”€ kernel_approximation
â”œâ”€â”€ kernel_ridge
â”œâ”€â”€ linear_model
â”œâ”€â”€ manifold
â”œâ”€â”€ metrics
â”œâ”€â”€ mixture
â”œâ”€â”€ model_selection
â”œâ”€â”€ multiclass
â”œâ”€â”€ multioutput
â”œâ”€â”€ naive_bayes
â”œâ”€â”€ neighbors
â”œâ”€â”€ neural_network
â”œâ”€â”€ pipeline
â”œâ”€â”€ preprocessing
â”œâ”€â”€ random_projection
â”œâ”€â”€ semi_supervised
â”œâ”€â”€ svm
â”œâ”€â”€ tree
â”œâ”€â”€ utils
â””â”€â”€ __check_build
```

---

# 2. **sklearn.base**

Estimator base classes and mixins

```
sklearn.base
â”‚â”€â”€ BaseEstimator
â”‚â”€â”€ ClassifierMixin
â”‚â”€â”€ RegressorMixin
â”‚â”€â”€ TransformerMixin
â”‚â”€â”€ ClusterMixin
â”‚â”€â”€ DensityMixin
â”‚â”€â”€ OutlierMixin
â”‚â”€â”€ MetaEstimatorMixin
â”‚â”€â”€ clone()
```

---

# 3. **sklearn.calibration**

Calibration tools:

```
sklearn.calibration
â”‚â”€â”€ CalibratedClassifierCV
â”‚â”€â”€ calibration_curve()
```

---

# 4. **sklearn.cluster**

Clustering algorithms:

```
sklearn.cluster
â”‚â”€â”€ KMeans
â”‚â”€â”€ MiniBatchKMeans
â”‚â”€â”€ BisectingKMeans
â”‚â”€â”€ AgglomerativeClustering
â”‚â”€â”€ FeatureAgglomeration
â”‚â”€â”€ MeanShift
â”‚â”€â”€ DBSCAN
â”‚â”€â”€ OPTICS
â”‚â”€â”€ Birch
â”‚â”€â”€ SpectralClustering
â”‚â”€â”€ AffinityPropagation
â”‚â”€â”€ cluster_optics_xi()
â”‚â”€â”€ estimate_bandwidth()
```

---

# 5. **sklearn.compose**

Column and feature composition:

```
sklearn.compose
â”‚â”€â”€ ColumnTransformer
â”‚â”€â”€ make_column_transformer()
â”‚â”€â”€ TransformedTargetRegressor
â”‚â”€â”€ make_column_selector()
```

---

# 6. **sklearn.covariance**

Covariance estimators:

```
sklearn.covariance
â”‚â”€â”€ EmpiricalCovariance
â”‚â”€â”€ EllipticEnvelope
â”‚â”€â”€ GraphicalLasso
â”‚â”€â”€ GraphicalLassoCV
â”‚â”€â”€ LedoitWolf
â”‚â”€â”€ OAS
â”‚â”€â”€ MinCovDet
â”‚â”€â”€ ShrunkCovariance
```

---

# 7. **sklearn.cross_decomposition**

Cross-decomposition methods:

```
sklearn.cross_decomposition
â”‚â”€â”€ PLSRegression
â”‚â”€â”€ PLSCanonical
â”‚â”€â”€ CCA
â”‚â”€â”€ PLSRegression
â”‚â”€â”€ PLSCanonical
```

---

# 8. **sklearn.datasets**

Dataset loaders & generators:

```
sklearn.datasets
â”‚â”€â”€ load_iris()
â”‚â”€â”€ load_wine()
â”‚â”€â”€ load_digits()
â”‚â”€â”€ load_breast_cancer()
â”‚â”€â”€ load_diabetes()
â”‚â”€â”€ fetch_20newsgroups()
â”‚â”€â”€ fetch_rcv1()
â”‚â”€â”€ fetch_kddcup99()
â”‚â”€â”€ fetch_lfw_people()
â”‚â”€â”€ make_classification()
â”‚â”€â”€ make_regression()
â”‚â”€â”€ make_blobs()
â”‚â”€â”€ make_gaussian_quantiles()
â”‚â”€â”€ make_hastie_10_2()
â”‚â”€â”€ make_moons()
â”‚â”€â”€ make_circles()
â”‚â”€â”€ load_svmlight_file()
â”‚â”€â”€ dump_svmlight_file()
```

---

# 9. **sklearn.decomposition**

Dimensionality reduction:

```
sklearn.decomposition
â”‚â”€â”€ PCA
â”‚â”€â”€ IncrementalPCA
â”‚â”€â”€ KernelPCA
â”‚â”€â”€ TruncatedSVD
â”‚â”€â”€ NMF
â”‚â”€â”€ DictionaryLearning
â”‚â”€â”€ FastICA
â”‚â”€â”€ FactorAnalysis
â”‚â”€â”€ SparsePCA
â”‚â”€â”€ MiniBatchSparsePCA
â”‚â”€â”€ LatentDirichletAllocation (LDA)
```

---

# 10. **sklearn.discriminant_analysis**

Linear discriminant models:

```
sklearn.discriminant_analysis
â”‚â”€â”€ LinearDiscriminantAnalysis
â”‚â”€â”€ QuadraticDiscriminantAnalysis
```

---

# 11. **sklearn.dummy**

Baseline models:

```
sklearn.dummy
â”‚â”€â”€ DummyClassifier
â”‚â”€â”€ DummyRegressor
```

---

# 12. **sklearn.ensemble**

Ensembles of estimators:

```
sklearn.ensemble
â”‚â”€â”€ RandomForestClassifier
â”‚â”€â”€ RandomForestRegressor
â”‚â”€â”€ ExtraTreesClassifier
â”‚â”€â”€ ExtraTreesRegressor
â”‚â”€â”€ AdaBoostClassifier
â”‚â”€â”€ AdaBoostRegressor
â”‚â”€â”€ GradientBoostingClassifier
â”‚â”€â”€ GradientBoostingRegressor
â”‚â”€â”€ HistGradientBoostingClassifier
â”‚â”€â”€ HistGradientBoostingRegressor
â”‚â”€â”€ BaggingClassifier
â”‚â”€â”€ BaggingRegressor
â”‚â”€â”€ IsolationForest
â”‚â”€â”€ StackingClassifier
â”‚â”€â”€ StackingRegressor
â”‚â”€â”€ VotingClassifier
â”‚â”€â”€ VotingRegressor
```

---

# 13. **sklearn.exceptions**

Error classes:

```
sklearn.exceptions
â”‚â”€â”€ ConvergenceWarning
â”‚â”€â”€ DataConversionWarning
â”‚â”€â”€ NotFittedError
```

---

# 14. **sklearn.experimental**

Experimental features:

```
sklearn.experimental
â”‚â”€â”€ enable_halving_search_cv
```

---

# 15. **sklearn.feature_extraction**

Generalized feature extraction:

```
sklearn.feature_extraction
â”‚
â”œâ”€â”€ text
â”‚   â”œâ”€â”€ CountVectorizer
â”‚   â”œâ”€â”€ TfidfVectorizer
â”‚   â”œâ”€â”€ TfidfTransformer
â”‚   â”œâ”€â”€ HashingVectorizer
â”‚   â””â”€â”€ ENGLISH_STOP_WORDS
â”‚
â””â”€â”€ image
    â”œâ”€â”€ PatchExtractor
    â”œâ”€â”€ extract_patches_2d()
    â”œâ”€â”€ img_to_graph()
    â””â”€â”€ grid_to_graph()
```

---

# 16. **sklearn.feature_selection**

Feature selection tools:

```
sklearn.feature_selection
â”‚â”€â”€ SelectKBest
â”‚â”€â”€ SelectPercentile
â”‚â”€â”€ SelectFpr
â”‚â”€â”€ SelectFdr
â”‚â”€â”€ SelectFwe
â”‚â”€â”€ RFE
â”‚â”€â”€ RFECV
â”‚â”€â”€ SelectFromModel
â”‚â”€â”€ VarianceThreshold
â”‚â”€â”€ chi2
â”‚â”€â”€ mutual_info_classif
â”‚â”€â”€ mutual_info_regression
â”‚â”€â”€ f_classif
â”‚â”€â”€ f_regression
```

---

# 17. **sklearn.gaussian_process**

Gaussian process models:

```
sklearn.gaussian_process
â”‚â”€â”€ GaussianProcessRegressor
â”‚â”€â”€ GaussianProcessClassifier
â”‚
â””â”€â”€ kernels
    â”œâ”€â”€ RBF
    â”œâ”€â”€ Matern
    â”œâ”€â”€ DotProduct
    â”œâ”€â”€ RationalQuadratic
    â”œâ”€â”€ ExpSineSquared
    â”œâ”€â”€ WhiteKernel
    â”œâ”€â”€ ConstantKernel
```

---

# 18. **sklearn.impute**

Missing data handling:

```
sklearn.impute
â”‚â”€â”€ SimpleImputer
â”‚â”€â”€ KNNImputer
â”‚â”€â”€ IterativeImputer
â”‚â”€â”€ MissingIndicator
```

---

# 19. **sklearn.inspection**

Inspection & interpretability:

```
sklearn.inspection
â”‚â”€â”€ permutation_importance()
â”‚â”€â”€ PartialDependenceDisplay
â”‚â”€â”€ DecisionBoundaryDisplay
```

---

# 20. **sklearn.isotonic**

Isotonic regression:

```
sklearn.isotonic
â”‚â”€â”€ IsotonicRegression
```

---

# 21. **sklearn.kernel_approximation**

Kernel approximation methods:

```
sklearn.kernel_approximation
â”‚â”€â”€ Nystroem
â”‚â”€â”€ RBFSampler
â”‚â”€â”€ AdditiveChi2Sampler
â”‚â”€â”€ PolynomialCountSketch
```

---

# 22. **sklearn.kernel_ridge**

Kernel ridge regression:

```
sklearn.kernel_ridge
â”‚â”€â”€ KernelRidge
```

---

# 23. **sklearn.linear_model**

Linear and generalized linear models:

```
sklearn.linear_model
â”‚â”€â”€ LinearRegression
â”‚â”€â”€ Ridge
â”‚â”€â”€ RidgeClassifier
â”‚â”€â”€ Lasso
â”‚â”€â”€ LassoCV
â”‚â”€â”€ ElasticNet
â”‚â”€â”€ ElasticNetCV
â”‚â”€â”€ Lars
â”‚â”€â”€ LassoLars
â”‚â”€â”€ OrthogonalMatchingPursuit
â”‚â”€â”€ BayesianRidge
â”‚â”€â”€ ARDRegression
â”‚â”€â”€ LogisticRegression
â”‚â”€â”€ LogisticRegressionCV
â”‚â”€â”€ SGDClassifier
â”‚â”€â”€ SGDRegressor
â”‚â”€â”€ PassiveAggressiveClassifier
â”‚â”€â”€ PassiveAggressiveRegressor
â”‚â”€â”€ RANSACRegressor
â”‚â”€â”€ HuberRegressor
â”‚â”€â”€ QuantileRegressor
â”‚â”€â”€ PoissonRegressor
â”‚â”€â”€ TweedieRegressor
â”‚â”€â”€ GammaRegressor
```

---

# 24. **sklearn.manifold**

Manifold learning:

```
sklearn.manifold
â”‚â”€â”€ TSNE
â”‚â”€â”€ Isomap
â”‚â”€â”€ MDS
â”‚â”€â”€ LocallyLinearEmbedding
â”‚â”€â”€ SpectralEmbedding
```

---

# 25. **sklearn.metrics**

Metrics, scorers, and pairwise functions:

```
sklearn.metrics
â”‚
â”œâ”€â”€ classification
â”‚   â”œâ”€â”€ accuracy_score
â”‚   â”œâ”€â”€ precision_score
â”‚   â”œâ”€â”€ recall_score
â”‚   â”œâ”€â”€ f1_score
â”‚   â”œâ”€â”€ confusion_matrix
â”‚   â”œâ”€â”€ classification_report
â”‚
â”œâ”€â”€ regression
â”‚   â”œâ”€â”€ r2_score
â”‚   â”œâ”€â”€ mean_squared_error
â”‚   â”œâ”€â”€ mean_absolute_error
â”‚
â”œâ”€â”€ clustering
â”‚   â”œâ”€â”€ silhouette_score
â”‚   â”œâ”€â”€ davies_bouldin_score
â”‚   â”œâ”€â”€ calinski_harabasz_score
â”‚
â””â”€â”€ pairwise
    â”œâ”€â”€ pairwise_distances
    â”œâ”€â”€ pairwise_kernels
    â”œâ”€â”€ rbf_kernel
    â”œâ”€â”€ cosine_similarity
```

---

# 26. **sklearn.mixture**

Mixture models:

```
sklearn.mixture
â”‚â”€â”€ GaussianMixture
â”‚â”€â”€ BayesianGaussianMixture
```

---

# 27. **sklearn.model_selection**

Model selection tools:

```
sklearn.model_selection
â”‚â”€â”€ train_test_split()
â”‚â”€â”€ KFold
â”‚â”€â”€ StratifiedKFold
â”‚â”€â”€ GroupKFold
â”‚â”€â”€ TimeSeriesSplit
â”‚â”€â”€ ShuffleSplit
â”‚â”€â”€ GridSearchCV
â”‚â”€â”€ RandomizedSearchCV
â”‚â”€â”€ HalvingGridSearchCV
â”‚â”€â”€ HalvingRandomSearchCV
â”‚â”€â”€ validation_curve()
â”‚â”€â”€ learning_curve()
â”‚â”€â”€ cross_val_score()
â”‚â”€â”€ cross_validate()
```

---

# 28. **sklearn.multiclass**

Strategies for multiclass learning:

```
sklearn.multiclass
â”‚â”€â”€ OneVsOneClassifier
â”‚â”€â”€ OneVsRestClassifier
â”‚â”€â”€ OutputCodeClassifier
```

---

# 29. **sklearn.multioutput**

Multi-output estimators:

```
sklearn.multioutput
â”‚â”€â”€ MultiOutputRegressor
â”‚â”€â”€ MultiOutputClassifier
```

---

# 30. **sklearn.naive_bayes**

Naive Bayes classifiers:

```
sklearn.naive_bayes
â”‚â”€â”€ GaussianNB
â”‚â”€â”€ MultinomialNB
â”‚â”€â”€ BernoulliNB
â”‚â”€â”€ CategoricalNB
â”‚â”€â”€ ComplementNB
```

---

# 31. **sklearn.neighbors**

Neighbor-based algorithms:

```
sklearn.neighbors
â”‚â”€â”€ KNeighborsClassifier
â”‚â”€â”€ KNeighborsRegressor
â”‚â”€â”€ NearestNeighbors
â”‚â”€â”€ RadiusNeighborsClassifier
â”‚â”€â”€ RadiusNeighborsRegressor
â”‚â”€â”€ KDTree
â”‚â”€â”€ BallTree
â”‚â”€â”€ DistanceMetric
```

---

# 32. **sklearn.neural_network**

Neural network models:

```
sklearn.neural_network
â”‚â”€â”€ MLPClassifier
â”‚â”€â”€ MLPRegressor
â”‚â”€â”€ BernoulliRBM
```

---

# 33. **sklearn.pipeline**

Pipelines and unions:

```
sklearn.pipeline
â”‚â”€â”€ Pipeline
â”‚â”€â”€ make_pipeline()
â”‚â”€â”€ FeatureUnion
â”‚â”€â”€ make_union()
```

---

# 34. **sklearn.preprocessing**

Preprocessing and feature engineering:

```
sklearn.preprocessing
â”‚â”€â”€ StandardScaler
â”‚â”€â”€ MinMaxScaler
â”‚â”€â”€ MaxAbsScaler
â”‚â”€â”€ RobustScaler
â”‚â”€â”€ Normalizer
â”‚â”€â”€ Binarizer
â”‚â”€â”€ KBinsDiscretizer
â”‚â”€â”€ OneHotEncoder
â”‚â”€â”€ OrdinalEncoder
â”‚â”€â”€ LabelEncoder
â”‚â”€â”€ LabelBinarizer
â”‚â”€â”€ PolynomialFeatures
â”‚â”€â”€ FunctionTransformer
â”‚â”€â”€ QuantileTransformer
â”‚â”€â”€ PowerTransformer
â”‚â”€â”€ SplineTransformer
```

---

# 35. **sklearn.random_projection**

Random projection methods:

```
sklearn.random_projection
â”‚â”€â”€ GaussianRandomProjection
â”‚â”€â”€ SparseRandomProjection
â”‚â”€â”€ johnson_lindenstrauss_min_dim()
```

---

# 36. **sklearn.semi_supervised**

Semi-supervised algorithms:

```
sklearn.semi_supervised
â”‚â”€â”€ LabelPropagation
â”‚â”€â”€ LabelSpreading
â”‚â”€â”€ SelfTrainingClassifier
```

---

# 37. **sklearn.svm**

Support vector machines:

```
sklearn.svm
â”‚â”€â”€ SVC
â”‚â”€â”€ SVR
â”‚â”€â”€ LinearSVC
â”‚â”€â”€ LinearSVR
â”‚â”€â”€ NuSVC
â”‚â”€â”€ NuSVR
â”‚â”€â”€ OneClassSVM
```

---

# 38. **sklearn.tree**

Decision trees and plotting utilities:

```
sklearn.tree
â”‚â”€â”€ DecisionTreeClassifier
â”‚â”€â”€ DecisionTreeRegressor
â”‚â”€â”€ ExtraTreeClassifier
â”‚â”€â”€ ExtraTreeRegressor
â”‚â”€â”€ export_graphviz()
â”‚â”€â”€ export_text()
â”‚â”€â”€ plot_tree()
```

---

# 39. **sklearn.utils**

Internal utilities:

```
sklearn.utils
â”‚â”€â”€ shuffle()
â”‚â”€â”€ resample()
â”‚â”€â”€ deprecated()
â”‚â”€â”€ check_array()
â”‚â”€â”€ check_is_fitted()
â”‚â”€â”€ Bunch
â”‚â”€â”€ estimator_html_repr()
â”‚â”€â”€ all_estimators()
â”‚â”€â”€ parallel_backend()
```

---

# âœ… **40. Extra subpackages not yet detailed**

Some submodules include internal helpers, plotting modules, settings, validation utilities, and experimental features not covered yet.
Below is a continuation of **ALL remaining modules and submodules**.

---

# 40. **sklearn.__check_build**

Internal, used to verify installation is compiled correctly:

```
sklearn.__check_build
â”‚â”€â”€ check_build()
â”‚â”€â”€ setup.py (internal)
```

---

# 41. **sklearn._loss**

Private submodule for advanced loss functions (used by HistGradientBoosting).

```
sklearn._loss
â”‚â”€â”€ loss.pyx (compiled)
â”‚â”€â”€ gradient_loss.py
â”‚â”€â”€ BaseLoss
â”‚â”€â”€ HalfBinomialLoss
â”‚â”€â”€ LeastSquares
â”‚â”€â”€ LeastAbsoluteError
â”‚â”€â”€ Poisson
â”‚â”€â”€ TweedieLoss
```

(Not part of public API but important for understanding internal behavior.)

---

# 42. **sklearn._plot**

Plotting utilities used by various model visualizers.

```
sklearn._plot
â”‚â”€â”€ partial_dependence
â”‚â”€â”€ decision_boundary
â”‚â”€â”€ tree
â”‚â”€â”€ utils
```

---

# 43. **sklearn._config**

Config and global runtime settings.

```
sklearn._config
â”‚â”€â”€ get_config()
â”‚â”€â”€ set_config()
â”‚â”€â”€ config_context()
â”‚â”€â”€ config (dictionary)
```

---

# 44. **sklearn._tags**

Estimator tags system used to validate estimator behavior.

```
sklearn.utils._tags
â”‚â”€â”€ _safe_tags()
â”‚â”€â”€ _safe_estimator_split()
â”‚â”€â”€ get_tags()
â”‚â”€â”€ set_estimator_type()
```

---

# 45. **sklearn._isotonic**

Backend implementation for IsotonicRegression.

```
sklearn._isotonic
â”‚â”€â”€ _isotonic_regression()
â”‚â”€â”€ _make_unique()
```

---

# 46. **sklearn._openmp_effective_n_threads**

Control of parallelism behavior via OpenMP.

```
sklearn._openmp_effective_n_threads
â”‚â”€â”€ _openmp_effective_n_threads()
```

---

# 47. **sklearn.neighbors._classification / _regression / _base**

Lower-level implementation classes:

```
sklearn.neighbors._base
â”‚â”€â”€ _fit()
â”‚â”€â”€ _kneighbors()
â”‚â”€â”€ _radius_neighbors()
```

---

# 48. **sklearn.svm._libsvm / _liblinear / _libsvm_sparse**

C/Cython bindings:

```
sklearn.svm._libsvm
â”‚â”€â”€ libsvm_train()
â”‚â”€â”€ libsvm_predict()
â”‚â”€â”€ libsvm_decision_function()

sklearn.svm._liblinear
â”‚â”€â”€ liblinear_train()
â”‚â”€â”€ liblinear_predict()

sklearn.svm._libsvm_sparse
â”‚â”€â”€ sparse kernel helpers
```

These are internal and used by SVC, SVR, LinearSVC, etc.

---

# 49. **sklearn.ensemble._hist_gradient_boosting**

Internals of histogram gradient boosting models.

```
sklearn.ensemble._hist_gradient_boosting
â”‚â”€â”€ gradient_boosting
â”‚â”€â”€ grower
â”‚â”€â”€ histogram
â”‚â”€â”€ loss
â”‚â”€â”€ predictor
â”‚â”€â”€ splitter
â”‚â”€â”€ threading
```

All written in Cython for performance.

---

# 50. **sklearn.utils.extmath**

Advanced mathematical helpers:

```
sklearn.utils.extmath
â”‚â”€â”€ randomized_svd()
â”‚â”€â”€ deterministic_vector_sign_flip()
â”‚â”€â”€ density()
â”‚â”€â”€ fast_logdet()
â”‚â”€â”€ safe_sparse_dot()
â”‚â”€â”€ row_norms()
```

---

# 51. **sklearn.utils.fixes**

Backward-compatibility patches:

```
sklearn.utils.fixes
â”‚â”€â”€ scipy / numpy compatibility helpers
â”‚â”€â”€ _import_numpy
â”‚â”€â”€ _mode (wrapper)
```

---

# 52. **sklearn.utils.graph**

Graph utilities used by clustering and manifold learning.

```
sklearn.utils.graph
â”‚â”€â”€ single_source_shortest_path_length()
â”‚â”€â”€ graph_shortest_path()
â”‚â”€â”€ csgraph_to_dense()
```

---

# 53. **sklearn.utils.sparsetools**

Sparse matrix utilities:

```
sklearn.utils.sparsetools
â”‚â”€â”€ csr_matvec()
â”‚â”€â”€ csc_matvec()
â”‚â”€â”€ csgraph components
```

---

# 54. **sklearn.utils.validation**

Validation and checking utilities:

```
sklearn.utils.validation
â”‚â”€â”€ check_array()
â”‚â”€â”€ check_X_y()
â”‚â”€â”€ check_consistent_length()
â”‚â”€â”€ check_random_state()
â”‚â”€â”€ check_is_fitted()
```

---

# 55. **sklearn.utils.metaestimators**

Meta-estimator creation utilities:

```
sklearn.utils.metaestimators
â”‚â”€â”€ if_delegate_has_method()
â”‚â”€â”€ available_if()
```

---

# 56. **sklearn.utils._bunch**

Simple dict-like container used throughout sklearn.

```
sklearn.utils.Bunch
â”‚â”€â”€ behaves like a dictionary with attribute access
```

---

# 57. **sklearn.utils._joblib**

Joblib wrapper for parallelism:

```
sklearn.utils._joblib
â”‚â”€â”€ Parallel
â”‚â”€â”€ delayed
â”‚â”€â”€ effective_n_jobs()
```

---

# 58. **sklearn.utils.murmurhash**

Hashing utilities used in hashing vectorizer:

```
sklearn.utils.murmurhash
â”‚â”€â”€ murmurhash3_32()
```

---

# 59. **sklearn.utils.random**

Random helpers:

```
sklearn.utils.random
â”‚â”€â”€ sample_without_replacement()
â”‚â”€â”€ shuffle()
â”‚â”€â”€ random_choice_csc()
```

---

# 60. **sklearn.utils._array_api**

Array API compatibility layer (NumPy, CuPy future-proofing)

```
sklearn.utils._array_api
â”‚â”€â”€ device()
â”‚â”€â”€ xp_is_numpy()
â”‚â”€â”€ get_namespace()
```

---

# 61. **sklearn.metrics._plot**

Plotting helpers for metrics visualizations:

```
sklearn.metrics._plot
â”‚â”€â”€ RocCurveDisplay
â”‚â”€â”€ PrecisionRecallDisplay
â”‚â”€â”€ ConfusionMatrixDisplay
â”‚â”€â”€ DetCurveDisplay
```

---

# 62. **sklearn.inspection._partial_dependence**

Backend for partial dependence:

```
sklearn.inspection._partial_dependence
â”‚â”€â”€ partial_dependence()
â”‚â”€â”€ _grid_from_X()
â”‚â”€â”€ _partial_dependence_bruteforce()
â”‚â”€â”€ _partial_dependence_fast()
```

---

# 63. **sklearn.metrics._scorer**

Scoring utilities used in model_selection:

```
sklearn.metrics._scorer
â”‚â”€â”€ make_scorer()
â”‚â”€â”€ SCORERS (dictionary of scorers)
```

---

# 64. **sklearn.utils._testing**

Internal testing helpers:

```
sklearn.utils._testing
â”‚â”€â”€ assert_allclose()
â”‚â”€â”€ assert_array_equal()
â”‚â”€â”€ create_memmap_backed_data()
```

---

# 65. **sklearn.utils._param_validation**

Parameter validation system:

```
sklearn.utils._param_validation
â”‚â”€â”€ validate_params()
â”‚â”€â”€ InvalidParameterError
```

---

# âœ”ï¸ **This now includes EVERY major public AND private module in scikit-learn.**

You now have the **most complete hierarchical list** of:

* public APIs
* internal APIs
* private submodules
* Cython backend components
* plotting helpers
* experimental modules
* utility systems
* validation APIs
* configuration tools

---