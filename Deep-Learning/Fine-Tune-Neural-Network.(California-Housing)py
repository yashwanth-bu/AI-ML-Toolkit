import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.preprocessing import StandardScaler
import numpy as np

# Assume RegressionNN class and scaler are defined as before

# === 1. Load your original scaler and model architecture ===
model = RegressionNN(input_dim=8)  # input_dim should match your features (8 for California Housing)

# === 2. Load saved best weights ===
checkpoint_path = "best_model.pth"
model.load_state_dict(torch.load(checkpoint_path))
model.train()  # Set model to training mode to fine-tune

# === 3. Prepare your new fine-tuning data ===
# Example: New dataset (replace with your actual fine-tuning dataset)
new_raw_X = np.array([
    [8.3252, 41, 6.9841, 1.0238, 322, 2.5556, 37.88, -122.23],
    [8.3014, 21, 6.2381, 0.9719, 2401, 2.1098, 37.86, -122.22]
])  # just example rows

new_raw_y = np.array([4.5, 3.2])  # example targets

# Normalize new data using original scaler (important!)
new_X_scaled = scaler.transform(new_raw_X)

# Convert to tensors
new_X_tensor = torch.tensor(new_X_scaled, dtype=torch.float32)
new_y_tensor = torch.tensor(new_raw_y.reshape(-1,1), dtype=torch.float32)

# Create DataLoader for fine-tuning
fine_tune_loader = DataLoader(TensorDataset(new_X_tensor, new_y_tensor), batch_size=2, shuffle=True)

# === 4. Setup optimizer and loss function for fine-tuning ===
# Optionally, use a smaller learning rate for fine-tuning
fine_tune_optimizer = optim.Adam(model.parameters(), lr=0.001)
loss_fn = nn.MSELoss()

# === 5. Fine-tuning loop ===
fine_tune_epochs = 20

for epoch in range(fine_tune_epochs):
    total_loss = 0
    for batch_X, batch_y in fine_tune_loader:
        fine_tune_optimizer.zero_grad()
        outputs = model(batch_X)
        loss = loss_fn(outputs, batch_y)
        loss.backward()
        fine_tune_optimizer.step()
        total_loss += loss.item()
    avg_loss = total_loss / len(fine_tune_loader)
    print(f"Fine-tune Epoch {epoch+1}/{fine_tune_epochs}, Loss: {avg_loss:.4f}")

# === 6. Save fine-tuned model if desired ===
torch.save(model.state_dict(), "fine_tuned_model.pth")
print("Fine-tuned model saved.")
