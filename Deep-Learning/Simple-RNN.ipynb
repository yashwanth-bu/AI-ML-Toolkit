{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b32ff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "345f53dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\"I love this movie\", 1),\n",
    "    (\"This film is terrible\", 0),\n",
    "    (\"What a great movie\", 1),\n",
    "    (\"I hated this film\", 0),\n",
    "    (\"Amazing acting and good story\", 1),\n",
    "    (\"Bad plot and boring\", 0),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ba9c288",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [word.split() for word in [sentence[0].lower() for sentence in data]]\n",
    "\n",
    "unique_tokens = set([word for sentence in tokens for word in sentence])\n",
    "\n",
    "vocab = {word: idx for idx, word in enumerate(unique_tokens, start=2)}\n",
    "(vocab['<PAD>'], vocab['<UNK>']) = (0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79daa4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.tensor(\n",
    "    pad_sequences(\n",
    "        [[vocab.get(word, vocab['<PAD>']) for word in token] for token in tokens],\n",
    "        padding=\"post\"\n",
    "    ),\n",
    "    dtype=torch.long\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b64d191",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tensor = torch.tensor([label for _, label in data], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf20ab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNNetwork(nn.Module):\n",
    "    def __init__(self, vocab_size, emd_dim):\n",
    "        super().__init__()\n",
    "        self.embedder = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=emd_dim,\n",
    "            padding_idx=vocab['<PAD>']\n",
    "        )\n",
    "        self.rnn = nn.RNN(emd_dim, 64, batch_first=True)\n",
    "        self.flinear = nn.Linear(64, 2) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        emb = self.embedder(x)\n",
    "        output, hidden = self.rnn(emb)\n",
    "        return self.flinear(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54295a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 50\n",
    "\n",
    "model = SimpleNNetwork(vocab_size, embedding_dim)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()   \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e173c217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss = 0.0000\n",
      "Epoch 2, Loss = 0.0000\n",
      "Epoch 3, Loss = 0.0000\n",
      "Epoch 4, Loss = 0.0000\n",
      "Epoch 5, Loss = 0.0000\n",
      "Epoch 6, Loss = 0.0000\n",
      "Epoch 7, Loss = 0.0000\n",
      "Epoch 8, Loss = 0.0000\n",
      "Epoch 9, Loss = 0.0000\n",
      "Epoch 10, Loss = 0.0000\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_tensor)\n",
    "    loss = criterion(output, y_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    total_loss += loss.item()\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(f\"Epoch {epoch + 1}, Loss = {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a1c3eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [\n",
    "    (\"I love this film\", 1),\n",
    "    (\"The plot is boring\", 0),\n",
    "    (\"Amazing movie\", 1),\n",
    "    (\"I hated the story\", 0),\n",
    "]\n",
    "\n",
    "test_tokens = [sentence.lower().split() for sentence, _ in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9b98232",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.tensor(\n",
    "    pad_sequences(\n",
    "        [[vocab.get(word, vocab['<PAD>']) for word in token] for token in test_tokens],\n",
    "        padding=\"post\"\n",
    "    ),\n",
    "    dtype=torch.long\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a000ea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = torch.tensor([label for _, label in test_data], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7d1dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(X_test)\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    print(\"Predictions:\", preds.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45fe6052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.25\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy : \", accuracy_score(y_test, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
